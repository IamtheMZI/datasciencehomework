{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.3.1 nltk==3.5 colorama==0.4.3 numpy==1.18.5 scikit_learn==0.23.2 Flask==1.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Intent File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Intent.json',encoding=\"utf-8\") as file:\n",
    "    intent_data_json = json.load(file)\n",
    "    \n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "labels = []\n",
    "responses = []\n",
    "\n",
    "response_json = {}\n",
    "for intent in intent_data_json['intents']:\n",
    "    for pattern in intent['text']:\n",
    "        training_sentences.append(pattern)\n",
    "        training_labels.append(intent['intent'])\n",
    "\n",
    "    response_json[intent['intent']] = intent['responses']\n",
    "    \n",
    "    responses.append(intent['responses'])\n",
    "    \n",
    "    if intent['intent'] not in labels:\n",
    "        labels.append(intent['intent'])\n",
    "\n",
    "with open('Intent_response.json','w',encoding=\"utf-8\") as fp:\n",
    "    json.dump(response_json, fp,indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_data_pd = pd.json_normalize(intent_data_json, record_path =['intents'])\n",
    "intent_data_pd[\"text\"].iloc[0].append(\"hi\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_labels, training_sentences):\n",
    "    num_classes = len(np.unique(training_labels))\n",
    "    lbl_encoder = LabelEncoder()\n",
    "    lbl_encoder.fit(training_labels)\n",
    "    training_labels = lbl_encoder.transform(training_labels)\n",
    "    vocab_size = 1000\n",
    "    embedding_dim = 16\n",
    "    max_len = 20\n",
    "    oov_token = \"<OOV>\"\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
    "    tokenizer.fit_on_texts(training_sentences)\n",
    "    word_index = tokenizer.word_index\n",
    "    sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "    padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    epochs = 500\n",
    "    \n",
    "#     old_stdout = sys.stdout # backup current stdout\n",
    "#     sys.stdout = open(os.devnull, \"w\")\n",
    "    history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs, verbose='1')\n",
    "#     sys.stdout = old_stdout # reset old stdout\n",
    "\n",
    "    model.save(\"chat_model\")\n",
    "\n",
    "    import pickle\n",
    "\n",
    "    # to save the fitted tokenizer\n",
    "    with open('tokenizer.pickle', 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # to save the fitted label encoder\n",
    "    with open('label_encoder.pickle', 'wb') as ecn_file:\n",
    "        pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "train(training_labels, training_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_user_name(input_query):\n",
    "    global user_data\n",
    "    user_data[\"User\"][\"Name\"] = input_query.split()[-1]\n",
    "    return None\n",
    "def get_user_name():\n",
    "    global user_data\n",
    "    return \"Your name is \" + user_data[\"User\"][\"Name\"] if user_data[\"User\"][\"Name\"] else \"Can you tell me your name?\"\n",
    "def greet_by_name():\n",
    "    global user_data\n",
    "    return \"Nice to Meet you \" + user_data[\"User\"][\"Name\"]\n",
    "def do_nothing():\n",
    "    pass\n",
    "def learn_new_question():\n",
    "    global training_sentences\n",
    "    global training_labels\n",
    "    global response_json\n",
    "    global intent_data_pd\n",
    "    print(Fore.GREEN + \"ChatBot:\" + str(\"[learnFunc]\") + Style.RESET_ALL , \"Can you tell me the question?\")\n",
    "    print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
    "    sentence = input()\n",
    "    training_sentences.append(sentence)\n",
    "    print(Fore.GREEN + \"ChatBot:\" + str(\"[learnFunc]\") + Style.RESET_ALL , \"Great. What is the answer?\")\n",
    "    print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
    "    answer = input()\n",
    "    print(Fore.GREEN + \"ChatBot:\" + str(\"[learnFunc]\") + Style.RESET_ALL , \"Last Question. What is the category?\")\n",
    "    print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
    "    label = input()\n",
    "    training_labels.append(label)\n",
    "    response_json[label] = response_json.get(label,[])\n",
    "    response_json[label].append(answer)\n",
    "    print(Fore.GREEN + \"ChatBot:\" + str(\"[learnFunc]\") + Style.RESET_ALL , \"Thanks. I will update my database soon!\")\n",
    "    \n",
    "    if not intent_data_pd[intent_data_pd.intent == label].empty:\n",
    "        intent_data_pd[intent_data_pd.intent == label][\"text\"].iloc[0].append(sentence)\n",
    "        intent_data_pd[intent_data_pd.intent == label][\"responses\"].iloc[0].append(answer)\n",
    "    else:\n",
    "        new_df = pd.DataFrame([[label,[sentence],[answer]]],columns=[\"intent\",\"text\",\"responses\"])\n",
    "        frames = [intent_data_pd,new_df]\n",
    "        intent_data_pd = pd.concat(frames,ignore_index=True)\n",
    "    store_current_data()\n",
    "def store_current_data():\n",
    "    global intent_data_pd\n",
    "    with open(\"Intent.json\",\"w\") as output_file:\n",
    "        new_json = {}\n",
    "        new_json[\"intents\"] = json.loads(intent_data_pd.to_json(orient=\"records\"))\n",
    "        json.dump(new_json, output_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "def update_model():\n",
    "    global training_sentences\n",
    "    global training_labels\n",
    "    global response_json\n",
    "    train(training_sentences, training_labels)\n",
    "    load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import colorama \n",
    "colorama.init()\n",
    "from colorama import Fore, Style, Back\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "with open(\"Intent_response.json\",encoding=\"utf-8\") as intent_file:\n",
    "    data = json.load(intent_file)\n",
    "with open(\"User.json\", encoding=\"utf-8\") as user_file:\n",
    "    user_data = json.load(user_file)\n",
    "\n",
    "def load_model():\n",
    "    # load trained model\n",
    "    model = keras.models.load_model('chat_model')\n",
    "\n",
    "    # load tokenizer object\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "\n",
    "    # load label encoder object\n",
    "    with open('label_encoder.pickle', 'rb') as enc:\n",
    "        lbl_encoder = pickle.load(enc)\n",
    "    return model,tokenizer,lbl_encoder\n",
    "\n",
    "def chat():   \n",
    "    model,tokenizer,lbl_encoder = load_model()\n",
    "    # parameters\n",
    "    max_len = 20\n",
    "    update_response = False\n",
    "    last_query = ''\n",
    "    \n",
    "    iters = 100\n",
    "    while iters:\n",
    "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
    "        inp = input()\n",
    "        if inp.lower() == \"quit\" or inp.lower() == \"exit\" or inp.lower() == \"bye\":\n",
    "            break\n",
    "\n",
    "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),truncating='post', maxlen=max_len))\n",
    "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
    "#             print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,tag)\n",
    "        iters = iters - 1\n",
    "        for key,val in response_json.items():\n",
    "#                 if tag == 'feedback':\n",
    "#                     update_response = True\n",
    "            if key == tag:\n",
    "                if \"Func\" in str(tag):\n",
    "                    resp_func = eval(val[0])\n",
    "                    _,resp = resp_func(inp)\n",
    "                else:\n",
    "                    resp = np.random.choice(val).replace(\"<HUMAN>\",user_data[\"User\"][\"Name\"])\n",
    "\n",
    "                print(Fore.GREEN + \"ChatBot:\" + str(tag) + Style.RESET_ALL , resp)\n",
    "                last_query = inp\n",
    "                break\n",
    "\n",
    "#         print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\n",
    "\n",
    "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_current_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>text</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>[Hi, Hi there, Hola, Hello, Hello there, Hya, ...</td>\n",
       "      <td>[Hi!, Hello!, Hola!,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GreetingResponseFunc</td>\n",
       "      <td>[I am called , My name is , My user is , This ...</td>\n",
       "      <td>[lambda input_query: (set_user_name(input_quer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CourtesyGreeting</td>\n",
       "      <td>[How are you?, Hi how are you?, Hello how are ...</td>\n",
       "      <td>[Hello, I am great, how are you?, Hello, how a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CourtesyGreetingResponse</td>\n",
       "      <td>[Good thanks!, I am good., Doing good, Great, ...</td>\n",
       "      <td>[Great! How can I help?, Good! how can I help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CurrentHumanQueryFunc</td>\n",
       "      <td>[What is my name?, What do you call me?, Who d...</td>\n",
       "      <td>[lambda input_query: (do_nothing(),get_user_na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NameQuery</td>\n",
       "      <td>[What is your name?, What could I call you?, W...</td>\n",
       "      <td>[You can call me Geni, You may call me Geni, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeedHelp</td>\n",
       "      <td>[I need some help, Help me, I require assistan...</td>\n",
       "      <td>[How can I help?, how can I help you?, What ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TimeQueryFunction</td>\n",
       "      <td>[What is the time?, What's the time?, Do you k...</td>\n",
       "      <td>[lambda x, y : \" I don't know the time \" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thanks</td>\n",
       "      <td>[OK thank you, OK thanks, OK, Thanks, Thank yo...</td>\n",
       "      <td>[No problem!, Happy to help!, Any time!, My pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NotTalking2U</td>\n",
       "      <td>[I am not talking to you, I was not talking to...</td>\n",
       "      <td>[OK, No problem, Right]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UnderstandQuery</td>\n",
       "      <td>[Do you understand what I am saying, Do you un...</td>\n",
       "      <td>[Well I would not be a very clever AI if I did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shutup</td>\n",
       "      <td>[Be quiet, Shut up, Stop talking, Enough talki...</td>\n",
       "      <td>[I am sorry to disturb you, Fine, sorry to dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Swearing</td>\n",
       "      <td>[fuck off, fuck, twat, shit]</td>\n",
       "      <td>[Please do not swear, How rude, That is not ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GoodBye</td>\n",
       "      <td>[Bye, Adios, See you later, Goodbye]</td>\n",
       "      <td>[See you later, Have a nice day, Bye! Come bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CourtesyGoodBye</td>\n",
       "      <td>[Thanks, bye, Thanks for the help, goodbye, Th...</td>\n",
       "      <td>[No problem, goodbye, Not a problem! Have a ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WhoAmI</td>\n",
       "      <td>[Can you see me?, Do you see me?, Can you see ...</td>\n",
       "      <td>[Let me see, Please look at the camera]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Clever</td>\n",
       "      <td>[You are very clever, You are a very clever gi...</td>\n",
       "      <td>[Thank you, I was trained that way, I was trai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Gossip</td>\n",
       "      <td>[I am bored gossip with me, Got any gossip, I ...</td>\n",
       "      <td>[Gregory said I respond to the current line no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Jokes</td>\n",
       "      <td>[Tell me a joke, Do you know any jokes, How ab...</td>\n",
       "      <td>[I met a Dutch girl with inflatable shoes last...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PodBayDoor</td>\n",
       "      <td>[Open the pod bay door, Can you open the pod b...</td>\n",
       "      <td>[I’m sorry, I’m afraid I can’t do that!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PodBayDoorResponse</td>\n",
       "      <td>[Why, Why not, Why can you not open the pod ba...</td>\n",
       "      <td>[It is classified, I could tell you but I woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SelfAware</td>\n",
       "      <td>[Can you prove you are self-aware, Can you pro...</td>\n",
       "      <td>[That is an interesting question, can you prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>learnFunc</td>\n",
       "      <td>[I want to teach you something new, Learn this...</td>\n",
       "      <td>[lambda input_query: (learn_new_question(),None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>updateDBFunc</td>\n",
       "      <td>[Update your database, Get your database updat...</td>\n",
       "      <td>[lambda input_query: (update_model(),None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>feedback</td>\n",
       "      <td>[That is not correct, That's not correct, That...</td>\n",
       "      <td>[Sorry to hear that. Can you tell me the corre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>applefruit</td>\n",
       "      <td>[what is apple]</td>\n",
       "      <td>[apple is a fruit]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      intent  \\\n",
       "0                   Greeting   \n",
       "1       GreetingResponseFunc   \n",
       "2           CourtesyGreeting   \n",
       "3   CourtesyGreetingResponse   \n",
       "4      CurrentHumanQueryFunc   \n",
       "5                  NameQuery   \n",
       "6                   NeedHelp   \n",
       "7          TimeQueryFunction   \n",
       "8                     Thanks   \n",
       "9               NotTalking2U   \n",
       "10           UnderstandQuery   \n",
       "11                    Shutup   \n",
       "12                  Swearing   \n",
       "13                   GoodBye   \n",
       "14           CourtesyGoodBye   \n",
       "15                    WhoAmI   \n",
       "16                    Clever   \n",
       "17                    Gossip   \n",
       "18                     Jokes   \n",
       "19                PodBayDoor   \n",
       "20        PodBayDoorResponse   \n",
       "21                 SelfAware   \n",
       "22                 learnFunc   \n",
       "23              updateDBFunc   \n",
       "24                  feedback   \n",
       "25                applefruit   \n",
       "\n",
       "                                                 text  \\\n",
       "0   [Hi, Hi there, Hola, Hello, Hello there, Hya, ...   \n",
       "1   [I am called , My name is , My user is , This ...   \n",
       "2   [How are you?, Hi how are you?, Hello how are ...   \n",
       "3   [Good thanks!, I am good., Doing good, Great, ...   \n",
       "4   [What is my name?, What do you call me?, Who d...   \n",
       "5   [What is your name?, What could I call you?, W...   \n",
       "6   [I need some help, Help me, I require assistan...   \n",
       "7   [What is the time?, What's the time?, Do you k...   \n",
       "8   [OK thank you, OK thanks, OK, Thanks, Thank yo...   \n",
       "9   [I am not talking to you, I was not talking to...   \n",
       "10  [Do you understand what I am saying, Do you un...   \n",
       "11  [Be quiet, Shut up, Stop talking, Enough talki...   \n",
       "12                       [fuck off, fuck, twat, shit]   \n",
       "13               [Bye, Adios, See you later, Goodbye]   \n",
       "14  [Thanks, bye, Thanks for the help, goodbye, Th...   \n",
       "15  [Can you see me?, Do you see me?, Can you see ...   \n",
       "16  [You are very clever, You are a very clever gi...   \n",
       "17  [I am bored gossip with me, Got any gossip, I ...   \n",
       "18  [Tell me a joke, Do you know any jokes, How ab...   \n",
       "19  [Open the pod bay door, Can you open the pod b...   \n",
       "20  [Why, Why not, Why can you not open the pod ba...   \n",
       "21  [Can you prove you are self-aware, Can you pro...   \n",
       "22  [I want to teach you something new, Learn this...   \n",
       "23  [Update your database, Get your database updat...   \n",
       "24  [That is not correct, That's not correct, That...   \n",
       "25                                    [what is apple]   \n",
       "\n",
       "                                            responses  \n",
       "0                               [Hi!, Hello!, Hola!,]  \n",
       "1   [lambda input_query: (set_user_name(input_quer...  \n",
       "2   [Hello, I am great, how are you?, Hello, how a...  \n",
       "3   [Great! How can I help?, Good! how can I help ...  \n",
       "4   [lambda input_query: (do_nothing(),get_user_na...  \n",
       "5   [You can call me Geni, You may call me Geni, C...  \n",
       "6   [How can I help?, how can I help you?, What ca...  \n",
       "7          [lambda x, y : \" I don't know the time \" ]  \n",
       "8   [No problem!, Happy to help!, Any time!, My pl...  \n",
       "9                             [OK, No problem, Right]  \n",
       "10  [Well I would not be a very clever AI if I did...  \n",
       "11  [I am sorry to disturb you, Fine, sorry to dis...  \n",
       "12  [Please do not swear, How rude, That is not ve...  \n",
       "13  [See you later, Have a nice day, Bye! Come bac...  \n",
       "14  [No problem, goodbye, Not a problem! Have a ni...  \n",
       "15            [Let me see, Please look at the camera]  \n",
       "16  [Thank you, I was trained that way, I was trai...  \n",
       "17  [Gregory said I respond to the current line no...  \n",
       "18  [I met a Dutch girl with inflatable shoes last...  \n",
       "19           [I’m sorry, I’m afraid I can’t do that!]  \n",
       "20  [It is classified, I could tell you but I woul...  \n",
       "21  [That is an interesting question, can you prov...  \n",
       "22  [lambda input_query: (learn_new_question(),None)]  \n",
       "23        [lambda input_query: (update_model(),None)]  \n",
       "24  [Sorry to hear that. Can you tell me the corre...  \n",
       "25                                 [apple is a fruit]  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
